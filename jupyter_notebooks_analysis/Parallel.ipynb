{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "# pip install --user ipyparallel\n",
    "# ipcluster nbextension enable --user\n",
    "\n",
    "# ipcluster start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipyparallel as ipp\n",
    "\n",
    "client = ipp.Client()\n",
    "lb_view = client.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lb_view.parallel()\n",
    "def f(x):\n",
    "    \"\"\"for parallel step source set identification on a group of 10 healthcodes\"\"\"\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import csv, os, pickle\n",
    "    from os.path import isfile, join\n",
    "    from os import listdir\n",
    "    import numpy as np\n",
    "    from datetime import datetime,timedelta\n",
    "    from dateutil.parser import parse\n",
    "\n",
    "    synapseCacheDir = \"/scratch/PI/euan/projects/mhc/data/synapseCache_v2/\"\n",
    "    table_path = \"/scratch/PI/euan/projects/mhc/data/tables/v2_data_subset/cardiovascular-HealthKitDataCollector-v1.tsv\"\n",
    "\n",
    "    def parse_healthkit_sources(file_path, HK_datatype):\n",
    "        \"\"\"Returns set of all (source, sourceIdentifier) that produces data of HK_datatype\"\"\"\n",
    "        tally_set=set()\n",
    "        #read in the data\n",
    "        dtype_dict=dict()\n",
    "        dtype_dict['names']=('startTime',\n",
    "                             'endTime',\n",
    "                             'type',\n",
    "                             'value',\n",
    "                             'unit',\n",
    "                             'source',\n",
    "                             'sourceIdentifier')\n",
    "        dtype_dict['formats']=(datetime,\n",
    "                               datetime,\n",
    "                               'S36',\n",
    "                               'i',\n",
    "                               'S36',\n",
    "                               'S36',\n",
    "                               'S36')\n",
    "        try:\n",
    "            data=np.genfromtxt(file_path,\n",
    "                               dtype=dtype_dict['formats'],\n",
    "                               names=dtype_dict['names'],\n",
    "                               delimiter=',',\n",
    "                               loose=True,\n",
    "                               invalid_raise=False, #needed since some lines are 1 column - issue with garmin...\n",
    "                               converters={0:lambda x: parse(x),\n",
    "                                           1:lambda x: parse(x)})\n",
    "        except:\n",
    "            print \"There was a problem importing\", file_path\n",
    "            return tally_set\n",
    "        #get the duration of each activity by day\n",
    "        try:\n",
    "            if data is not None and len(data):\n",
    "                for row in range(len(data)):\n",
    "                    if data['startTime'][row] is not None:\n",
    "                        datatype = data['type'][row]\n",
    "                        source = data['source'][row]\n",
    "                        sourceIdentifier = data['sourceIdentifier'][row]\n",
    "                        if datatype == HK_datatype:\n",
    "                            tally_set.add((source, sourceIdentifier))\n",
    "        except:\n",
    "            print data, type(data)\n",
    "        return tally_set\n",
    "\n",
    "    def SubjectSources(data_table, subject):\n",
    "        \"\"\"Iterates over rows of data_table with subject's data and \n",
    "        finds the set of sourceIdentifiers that produce HKQuantityTypeIdentifierStepCounts\"\"\"\n",
    "        sourses = set()\n",
    "        data_subject = data_table[data_table[\"healthCode\"]==subject]\n",
    "        for row in data_subject:\n",
    "            blob_name=row['data']\n",
    "            if blob_name.endswith('NA'):\n",
    "                continue \n",
    "            synapseCacheFile=get_synapse_cache_entry(synapseCacheDir,blob_name)\n",
    "            sourses.update(parse_healthkit_sources(synapseCacheFile, \"HKQuantityTypeIdentifierStepCount\"))\n",
    "        return sourses\n",
    "\n",
    "    data_table= pickle.load( open(os.path.join(\"/home/hershman\",\"cardiovascular-HealthKitDataCollector-v1.p\"), \"rb\" ) )\n",
    "    def ApplySubjects(subject_fn, data_table = data_table, function = SubjectSources):\n",
    "        results={}\n",
    "\n",
    "        subjects=open(subject_fn,'r').read().strip().split('\\n')\n",
    "        for subject in subjects:\n",
    "            results[subject] = function(data_table, subject)\n",
    "        return results\n",
    "\n",
    "    subjects_forumula = \"/scratch/PI/euan/projects/mhc/data/tables/v2_data_subset/subjects/healthkit_data/x%d\"\n",
    "\n",
    "    return ApplySubjects(data_table, subjects_forumula % x, SubjectSources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = f.map(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeError",
     "evalue": "one or more exceptions from call to method: f\n[0:apply]: UnicodeDecodeError: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)\n[10:apply]: UnicodeDecodeError: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)\n[1:apply]: UnicodeDecodeError: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)\n[7:apply]: UnicodeDecodeError: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)\n.... 96 more exceptions ...",
     "output_type": "error",
     "traceback": [
      "[0:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mApplySubjects\u001b[0;34m(subject_fn, data_table, function)\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)",
      "",
      "[10:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mApplySubjects\u001b[0;34m(subject_fn, data_table, function)\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)",
      "",
      "[1:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mApplySubjects\u001b[0;34m(subject_fn, data_table, function)\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)",
      "",
      "[7:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m",
      "\u001b[0;32m<ipython-input-38-1ca11af44aa4>\u001b[0m in \u001b[0;36mApplySubjects\u001b[0;34m(subject_fn, data_table, function)\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xa8 in position 144: ordinal not in range(128)",
      "",
      "... 96 more exceptions ..."
     ]
    }
   ],
   "source": [
    "ar.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ipyparallel.client.asyncresult.AsyncMapResult"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Exploring MHC Pipeline to find outliers.ipynb\r\n",
      "2.1 Outlier Subject Data - diving in.ipynb\r\n",
      "2.3 Outlier Subject Data - Sources.ipynb\r\n",
      "2 Outlier Subject Data.ipynb\r\n",
      "aggregators.py\r\n",
      "aggregators.pyc\r\n",
      "assemble_results_across_subjects.py\r\n",
      "assemble_results_across_subjects.sh\r\n",
      "cache.p\r\n",
      "cardiovascular-HealthKitDataCollector-v1.p\r\n",
      "filter_and_qc.py\r\n",
      "filter_and_qc.sh\r\n",
      "filters.py\r\n",
      "get_activity_fraction_and_duration_appv2.activity_only.sh\r\n",
      "get_activity_fraction_and_duration_appv2.healthkit.sh\r\n",
      "get_activity_fraction_and_duration_appv2.py\r\n",
      "get_objective_metrics_for_gwas.py\r\n",
      "get_objective_metrics_for_gwas.sh\r\n",
      "health_kit_metrics.py\r\n",
      "load_summaries.py\r\n",
      "measure_intervention_effects.R\r\n",
      "motion_tracker_metrics.py\r\n",
      "\u001b[0m\u001b[38;5;27mmyheartcounts-master\u001b[0m/\r\n",
      "outprefix\r\n",
      "Parallel.ipynb\r\n",
      "qc_metrics.py\r\n",
      "\u001b[38;5;27mR\u001b[0m/\r\n",
      "R test (crashes).ipynb\r\n",
      "sbatch.healthkit.sh\r\n",
      "sbatch.motiontracker.sh\r\n",
      "synapse_parser.py\r\n",
      "synapse_parser.pyc\r\n",
      "table_loader.py\r\n",
      "table_loader.pyc\r\n",
      "table_parser.py\r\n",
      "table_parser.pyc\r\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "ls /home/hershman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "# The Client allows us to use the engines interactively.\n",
    "# We simply pass Client the name of the cluster profile we\n",
    "# are using.\n",
    "In [2]: c = Client(profile='mycluster')\n",
    "In [3]: v = c[:]\n",
    "\n",
    "In [3]: c.ids\n",
    "Out[3]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "In [4]: run pidigits.py\n",
    "\n",
    "In [6]: files = [filestring % {'i':i} for i in range(1,16)]\n",
    "\n",
    "In [7]: files\n",
    "Out[7]:\n",
    "['pi200m.ascii.01of20',\n",
    " 'pi200m.ascii.02of20',\n",
    " 'pi200m.ascii.03of20',\n",
    " 'pi200m.ascii.04of20',\n",
    " 'pi200m.ascii.05of20',\n",
    " 'pi200m.ascii.06of20',\n",
    " 'pi200m.ascii.07of20',\n",
    " 'pi200m.ascii.08of20',\n",
    " 'pi200m.ascii.09of20',\n",
    " 'pi200m.ascii.10of20',\n",
    " 'pi200m.ascii.11of20',\n",
    " 'pi200m.ascii.12of20',\n",
    " 'pi200m.ascii.13of20',\n",
    " 'pi200m.ascii.14of20',\n",
    " 'pi200m.ascii.15of20']\n",
    "\n",
    "# download the data files if they don't already exist:\n",
    "In [8]: v.map(fetch_pi_file, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
