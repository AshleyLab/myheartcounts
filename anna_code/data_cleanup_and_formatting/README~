#USE R.2.3.0 AND PYTHON 2.7.6 (module load r/3.2.0 ; module load python/2.7.6) 

#PIPELINE FOR DATA CLEANUP AND FORMATTING


#UPDATE THE LIST OF SUBJECTS IN OUR STUDY 
python get_subjects.py 

#UPDATE THE LIST OF TABLES IN OUR STUDY AND NOTE ANY NEW TABLES THAT WERE ADDED IN THE DATA DOWNLOAD 
python get_tables.py 

#CLEANUP DATA 
#json files 
python cleanup_json.py 
#csv blob files -- note: 86000 will change, provide the number of records in the largest csv blob summary table 
qsub -cwd -V -t 1-86000:500 cleanup.sh 
#GET RID OF THE LOG FILES GENERATED BY QSUB 
rm cleanup.sh.e* 
rm cleanup.sh.o* 

#REFORMAT AND CONCATENATE DATA FOR SUBJECTS 
python split_tables_for_concat.py

for i in `find 6minwalktables/ subset*`
do
qsub -cwd -v fname=$i -V  concat_6min_walk_and_displacement.sh
done 


for i in `find healthkittables/ cardiovascular*`
do
qsub -cwd -v fname=$i -V concat_healthkit.sh 
done 

for i in `find motiontrackertables/ cardiovascular*`
do
qsub -cwd -v fname=$i -V concat_motiontracker.sh
done

for i in `find carddisptables/ cardiovascular*`
do
qsub -cwd -v fname=$i -V concat_card_displacement.sh
done 
